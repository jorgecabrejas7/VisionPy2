{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasetmaker\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "from onlypores import onlypores as op\n",
    "from UTXCTregister import UTXCTregister as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sequence(folder_path):\n",
    "    \"\"\"\n",
    "    Read a sequence of TIFF files in a folder as a 3D volume.\n",
    "    \n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing TIFF files.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 3D array where each slice corresponds to a TIFF file.\n",
    "    \"\"\"\n",
    "\n",
    "    # List and sort the TIFF files\n",
    "    tiff_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if (f.endswith('.tiff') or f.endswith('.tif'))])\n",
    "\n",
    "    tiff_sequence = tifffile.TiffSequence(tiff_files)\n",
    "    \n",
    "    # Get the total number of TIFF files\n",
    "    total_files = len(tiff_files)\n",
    "    \n",
    "    # Read each TIFF file and update progress\n",
    "    volume = []\n",
    "    with tqdm(total=total_files, desc=\"Progress\") as pbar:\n",
    "        for i, file_path in enumerate(tiff_files):\n",
    "            slice_data = tifffile.imread(file_path)\n",
    "            volume.append(slice_data)\n",
    "            \n",
    "            # Update progress\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return np.array(volume)\n",
    "\n",
    "def write_sequence(folder_path, name, volume):\n",
    "    \"\"\"\n",
    "    Save a 3D volume as a sequence of TIFF files in a folder.\n",
    "    \n",
    "    Args:\n",
    "    folder_path (str): Path to the folder where TIFF files will be saved.\n",
    "    name (str): Name of the TIFF files.\n",
    "    volume (numpy.ndarray): A 3D array where each slice corresponds to an image.\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = folder_path / name\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    Path(folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save each slice as a TIFF file with progress bar\n",
    "    with tqdm(total=volume.shape[0], desc=\"Saving\") as pbar:\n",
    "        for i in range(volume.shape[0]):\n",
    "            tifffile.imwrite(f\"{folder_path}/{name}_{i:04d}.tif\", volume[i])\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(\"Saving complete.\")\n",
    "\n",
    "def to_matrix(string):\n",
    "\n",
    "    matrix1 = float(string[2:17])\n",
    "\n",
    "    matrix2 = float(string[17:33])\n",
    "\n",
    "    matrix3 = float(string[33:49])\n",
    "\n",
    "    matrix4 = float(string[53:68])\n",
    "\n",
    "    matrix5 = float(string[68:84])\n",
    "\n",
    "    matrix6 = float(string[84:100])\n",
    "\n",
    "    matrix7 = float(string[105:121])\n",
    "\n",
    "    matrix8 = float(string[121:137])\n",
    "\n",
    "    matrix9 = float(string[137:151])\n",
    "\n",
    "    matrix = np.array([[matrix1,matrix2,matrix3],[matrix4,matrix5,matrix6],[matrix7,matrix8,matrix9]])\n",
    "\n",
    "    return matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\11_database\\Database.csv')\n",
    "\n",
    "database = database.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Original', 'Eq', 'Frontal 90 Right', 'XCT padded', 'Binary',\n",
       "       'Material Mask', 'Onlypores', 'UT', 'UT aligned', 'UT aligned amp',\n",
       "       'UT registered', 'UT lente', 'UT aligned lente', 'UT aligned amp lente',\n",
       "       'UT registered lente', 'Registration Parameters',\n",
       "       'Registration Parameters lente', 'Dataset PatchvsVolfrac 3x3',\n",
       "       'Dataset PatchvsVolfrac lente 3x3', 'Dataset PatchvsVolfrac 5x5',\n",
       "       'Dataset PatchvsVolfrac lente 5x5', 'Dataset PatchvsVolfrac 7x7',\n",
       "       'Dataset PatchvsVolfrac lente 7x7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetsFolder = Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\04_ML_data\\Airbus\\Panel Pegaso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = database['Id']\n",
    "\n",
    "onlypores_paths = database['Onlypores']\n",
    "\n",
    "masks = database['Material Mask']\n",
    "\n",
    "datasets1x3 = database['Dataset PatchvsVolfrac 3x3']\n",
    "\n",
    "datasets1x5 = database['Dataset PatchvsVolfrac 5x5']\n",
    "\n",
    "datasets1x7 = database['Dataset PatchvsVolfrac 7x7']\n",
    "\n",
    "datasets1x3_lente = database['Dataset PatchvsVolfrac lente 3x3']\n",
    "\n",
    "datasets1x5_lente = database['Dataset PatchvsVolfrac lente 5x5']\n",
    "\n",
    "datasets1x7_lente = database['Dataset PatchvsVolfrac lente 7x7']\n",
    "\n",
    "rfs = database['UT registered']\n",
    "\n",
    "rfs_lente = database['UT registered lente']\n",
    "\n",
    "rfs_og = database['UT']\n",
    "\n",
    "rfs_lente_og = database['UT lente']\n",
    "\n",
    "registration_parameters = database['Registration Parameters']\n",
    "\n",
    "registration_parameters_lente = database['Registration Parameters lente']\n",
    "\n",
    "frontals  = database['Frontal 90 Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alberto.vicente\\AppData\\Local\\Temp\\ipykernel_10276\\1479614042.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasets1x3[datasets1x3 != 0] = None\n"
     ]
    }
   ],
   "source": [
    "datasets1x3[datasets1x3 != 0] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ids)):\n",
    "\n",
    "#     if (onlypores_paths[i] != None) and (masks[i] != None) and (rfs[i] != None):\n",
    "#         print(f\"Processing {ids[i]}\")\n",
    "#         try:\n",
    "#             #Check if is there a remaining dataset to be processed\n",
    "#             if(datasets1x3[i]==None) or (datasets2x3[i]==None) or (datasets1x5[i]==None) or (datasets2x5[i]==None) or (datasets1x7[i]==None) or (datasets2x7[i]==None):\n",
    "\n",
    "#                 print('Loading:',onlypores_paths[i])\n",
    "#                 onlypores = read_sequence(onlypores_paths[i])\n",
    "#                 print('Loading:',masks[i])\n",
    "#                 mask = read_sequence(masks[i])\n",
    "#                 print('Loading:',rfs[i])\n",
    "#                 rf = tifffile.imread(rfs[i])\n",
    "\n",
    "#                 output_folder = DatasetsFolder / str(ids[i])\n",
    "\n",
    "#                 if output_folder.exists() == False:\n",
    "#                     output_folder.mkdir()\n",
    "                \n",
    "#                 output_folder = output_folder / 'MonoElement'\n",
    "\n",
    "#                 if output_folder.exists() == False:\n",
    "#                     output_folder.mkdir()\n",
    "\n",
    "#                 if (datasets1x3[i]==None) or (datasets2x3[i]==None):\n",
    "#                     print('Processing 3x3')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=3)\n",
    "#                     datasets1x3[i] = str(output_folder / 'patch_vs_volfrac_3.csv')\n",
    "#                     datasets2x3[i] = str(output_folder / 'patch_vs_patch_3.csv')\n",
    "#                 if (datasets1x5[i]==None) or (datasets2x5[i]==None):\n",
    "#                     print('Processing 5x5')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=5)\n",
    "#                     datasets1x5[i] = str(output_folder / 'patch_vs_volfrac_5.csv')\n",
    "#                     datasets2x5[i] = str(output_folder / 'patch_vs_patch_5.csv')\n",
    "#                 if (datasets1x7[i]==None) or (datasets2x7[i]==None):\n",
    "#                     print('Processing 7x7')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=7)\n",
    "#                     datasets1x7[i] = str(output_folder / 'patch_vs_volfrac_7.csv')\n",
    "#                     datasets2x7[i] = str(output_folder / 'patch_vs_patch_7.csv')\n",
    "            \n",
    "#             else:\n",
    "#                 print('All datasets already processed')\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {ids[i]}\")\n",
    "#             print(e)\n",
    "    \n",
    "#     if (onlypores_paths[i] != None) and (masks[i] != None) and (rfs_lente[i] != None):\n",
    "#         print(f\"Processing {ids[i]} lente\")\n",
    "#         try:\n",
    "#             #Check if is there a remaining dataset to be processed\n",
    "#             if(datasets1x3_lente[i]==None) or (datasets2x3_lente[i]==None) or (datasets1x5_lente[i]==None) or (datasets2x5_lente[i]==None) or (datasets1x7_lente[i]==None) or (datasets2x7_lente[i]==None):\n",
    "\n",
    "#                 print('Loading:',onlypores_paths[i])\n",
    "#                 onlypores = read_sequence(onlypores_paths[i])\n",
    "#                 print('Loading:',masks[i])\n",
    "#                 mask = read_sequence(masks[i])\n",
    "#                 print('Loading:',rfs_lente[i])\n",
    "#                 rf = tifffile.imread(rfs_lente[i])\n",
    "\n",
    "#                 output_folder = DatasetsFolder / str(ids[i])\n",
    "\n",
    "#                 if output_folder.exists() == False:\n",
    "#                     output_folder.mkdir()\n",
    "\n",
    "#                 output_folder = output_folder / 'MonoElementLens'\n",
    "\n",
    "#                 if output_folder.exists() == False:\n",
    "#                     output_folder.mkdir()\n",
    "\n",
    "#                 if (datasets1x3_lente[i]==None) or (datasets2x3_lente[i]==None):\n",
    "#                     print('Processing 3x3')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=3)\n",
    "#                     datasets1x3_lente[i] = str(output_folder / 'patch_vs_volfrac_3.csv')\n",
    "#                     datasets2x3_lente[i] = str(output_folder / 'patch_vs_patch_3.csv')\n",
    "#                 if (datasets1x5_lente[i]==None) or (datasets2x5_lente[i]==None):\n",
    "#                     print('Processing 5x5')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=5)\n",
    "#                     datasets1x5_lente[i] = str(output_folder / 'patch_vs_volfrac_5.csv')\n",
    "#                     datasets2x5_lente[i] = str(output_folder / 'patch_vs_patch_5.csv')\n",
    "#                 if (datasets1x7_lente[i]==None) or (datasets2x7_lente[i]==None):\n",
    "#                     print('Processing 7x7')\n",
    "#                     datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=7)\n",
    "#                     datasets1x7_lente[i] = str(output_folder / 'patch_vs_volfrac_7.csv')\n",
    "#                     datasets2x7_lente[i] = str(output_folder / 'patch_vs_patch_7.csv')\n",
    "            \n",
    "#             else:\n",
    "#                 print('All datasets already processed')\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {ids[i]}\")\n",
    "#             print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1_26\n",
      "Loading xct\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ids)):\n",
    "\n",
    "    if (onlypores_paths[i] != None) and (masks[i] != None) and (rfs[i] != None):\n",
    "        print(f\"Processing {ids[i]}\")\n",
    "        try:\n",
    "            #Check if is there a remaining dataset to be processed\n",
    "            if(datasets1x3[i]==None) or (datasets1x5[i]==None) or (datasets1x7[i]==None):\n",
    "                \n",
    "                print('Loading xct')\n",
    "                #get onlypores\n",
    "                xct = tifffile.imread(frontals[i])\n",
    "                xct = np.swapaxes(xct, 0, 1)\n",
    "                xct = np.swapaxes(xct, 1, 2)\n",
    "                print('Loading rf')\n",
    "                rf = tifffile.imread(rfs_og[i])\n",
    "                rf = np.swapaxes(rf, 0, 1)\n",
    "                rf = np.swapaxes(rf, 1, 2)\n",
    "                print('Aplying registration')\n",
    "                parameters = to_matrix(registration_parameters[i])\n",
    "                xct = reg.apply_registration(rf,xct,parameters)\n",
    "                rf = np.swapaxes(rf, 1, 2)\n",
    "                rf = np.swapaxes(rf, 0, 1)\n",
    "                xct = np.swapaxes(xct, 1, 2)\n",
    "                xct = np.swapaxes(xct, 0, 1)\n",
    "                print('Generating onlypores')\n",
    "                onlypores, mask, _ = op.onlypores_parallel(xct)\n",
    "                print('Onlypores generated')\n",
    "\n",
    "                output_folder = DatasetsFolder / str(ids[i])\n",
    "\n",
    "                if output_folder.exists() == False:\n",
    "                    output_folder.mkdir()\n",
    "                \n",
    "                output_folder = output_folder / 'MonoElement'\n",
    "\n",
    "                if output_folder.exists() == False:\n",
    "                    output_folder.mkdir()\n",
    "\n",
    "                if (datasets1x3[i]==None) :\n",
    "                    print('Processing 3x3')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=3)\n",
    "                    datasets1x3[i] = str(output_folder / 'patch_vs_volfrac_3.csv')\n",
    "                if (datasets1x5[i]==None) :\n",
    "                    print('Processing 5x5')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=5)\n",
    "                    datasets1x5[i] = str(output_folder / 'patch_vs_volfrac_5.csv')\n",
    "                if (datasets1x7[i]==None) :\n",
    "                    print('Processing 7x7')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=7)\n",
    "                    datasets1x7[i] = str(output_folder / 'patch_vs_volfrac_7.csv')\n",
    "            \n",
    "            else:\n",
    "                print('All datasets already processed')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ids[i]}\")\n",
    "            print(e)\n",
    "    \n",
    "    if (onlypores_paths[i] != None) and (masks[i] != None) and (rfs_lente[i] != None):\n",
    "        print(f\"Processing {ids[i]} lente\")\n",
    "        try:\n",
    "            #Check if is there a remaining dataset to be processed\n",
    "            if(datasets1x3_lente[i]==None) or (datasets1x5_lente[i]==None) or (datasets1x7_lente[i]==None):\n",
    "\n",
    "                \n",
    "                print('Loading rf')\n",
    "                rf = tifffile.imread(rfs_lente_og[i])\n",
    "                rf = np.swapaxes(rf, 0, 1)\n",
    "                rf = np.swapaxes(rf, 1, 2)\n",
    "                print('Aplying registration')\n",
    "                parameters = to_matrix(registration_parameters[i])\n",
    "                xct = reg.apply_registration(rf,xct,parameters)\n",
    "                rf = np.swapaxes(rf, 1, 2)\n",
    "                rf = np.swapaxes(rf, 0, 1)\n",
    "                xct = np.swapaxes(xct, 1, 2)\n",
    "                xct = np.swapaxes(xct, 0, 1)\n",
    "                print('Generating onlypores')\n",
    "                onlypores, mask, _ = op.onlypores_parallel(xct)\n",
    "                print('Onlypores generated')\n",
    "\n",
    "                output_folder = DatasetsFolder / str(ids[i])\n",
    "\n",
    "                if output_folder.exists() == False:\n",
    "                    output_folder.mkdir()\n",
    "\n",
    "                output_folder = output_folder / 'MonoElementLens'\n",
    "\n",
    "                if output_folder.exists() == False:\n",
    "                    output_folder.mkdir()\n",
    "\n",
    "                if (datasets1x3_lente[i]==None) :\n",
    "                    print('Processing 3x3')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=3)\n",
    "                    datasets1x3_lente[i] = str(output_folder / 'patch_vs_volfrac_3.csv')\n",
    "                if (datasets1x5_lente[i]==None) :\n",
    "                    print('Processing 5x5')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=5)\n",
    "                    datasets1x5_lente[i] = str(output_folder / 'patch_vs_volfrac_5.csv')\n",
    "                if (datasets1x7_lente[i]==None) :\n",
    "                    print('Processing 7x7')\n",
    "                    datasetmaker.main(onlypores,mask,rf,output_folder,ut_patch_size=7)\n",
    "                    datasets1x7_lente[i] = str(output_folder / 'patch_vs_volfrac_7.csv')\n",
    "            \n",
    "            else:\n",
    "                print('All datasets already processed')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ids[i]}\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "database['Dataset PatchvsVolfrac 3x3'] = datasets1x3\n",
    "\n",
    "database['Dataset PatchvsVolfrac 5x5'] = datasets1x5\n",
    "\n",
    "database['Dataset PatchvsVolfrac 7x7'] = datasets1x7\n",
    "\n",
    "database['Dataset PatchvsVolfrac lente 3x3'] = datasets1x3_lente\n",
    "\n",
    "database['Dataset PatchvsVolfrac lente 5x5'] = datasets1x5_lente\n",
    "\n",
    "database['Dataset PatchvsVolfrac lente 7x7'] = datasets1x7_lente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.to_csv(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\11_database\\Database.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisionPyKernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
